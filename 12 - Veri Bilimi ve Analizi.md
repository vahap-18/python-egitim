## ğŸ“Œ 12.1 Veri Bilimine GiriÅŸ

Veri bilimi, geniÅŸ bir veri kÃ¼mesinden anlamlÄ± bilgilerin Ã§Ä±karÄ±lmasÄ± iÃ§in Ã§eÅŸitli teknikler ve yÃ¶ntemler kullanan bir disiplindir. Temel olarak, veri analizi ve istatistikten makine Ã¶ÄŸrenimine kadar birÃ§ok alana yayÄ±lmaktadÄ±r.

### âœ… **Veri Bilimi Nedir ve Temel Kavramlar**

- **Veri Bilimi**: Disiplinler arasÄ± bir alan olup, veri analizi, istatistik ve bilgi teknolojilerini bir araya getirir. Veri bilimi, verileri analiz ederek karar alma sÃ¼reÃ§lerine katkÄ±da bulunur.
- **Temel Kavramlar**:
  - **Veri**: Ã‡eÅŸitli biÃ§imlerde (sayÄ±sal, metin, gÃ¶rsel vb.) bulunan bilgiler.
  - **Modelleme**: Verilerin anlamlÄ± bir ÅŸekilde yapÄ±landÄ±rÄ±lmasÄ± iÃ§in kullanÄ±lan teknikler.
  - **Makine Ã–ÄŸrenimi**: Bilgisayarlara verilerden Ã¶ÄŸrenme yeteneÄŸi kazandÄ±rma sÃ¼reci.

---

### âœ… **Veri Biliminin Uygulama AlanlarÄ±**

Veri bilimi, birÃ§ok sektÃ¶rde kullanÄ±lmaktadÄ±r:
- **Finans**: Risk analizi, piyasa trendlerinin tahmini.
- **Pazarlama**: MÃ¼ÅŸteri davranÄ±ÅŸlarÄ±nÄ±n analizi, hedef kitle oluÅŸturma.
- **SaÄŸlÄ±k**: HastalÄ±k tahminleri, tedavi sonuÃ§larÄ±nÄ±n deÄŸerlendirilmesi.
- **E-ticaret**: SatÄ±ÅŸ tahminleri, stok yÃ¶netimi.

Bu alanlardaki uygulamalar, iÅŸletmelerin daha etkili stratejiler geliÅŸtirmesine ve rekabet avantajÄ± saÄŸlamasÄ±na yardÄ±mcÄ± olur.

---

### âœ… **Veri Bilimi SÃ¼reci ve AdÄ±mlarÄ±**

Veri bilimi sÃ¼reci genellikle ÅŸu adÄ±mlarÄ± iÃ§erir:
1. **Veri Toplama**: Verilerin Ã§eÅŸitli kaynaklardan toplanmasÄ±.
2. **Veri Temizleme**: Eksik, hatalÄ± veya tutarsÄ±z verilerin dÃ¼zeltilmesi.
3. **Veri KeÅŸfi**: Verilerin analizi ve gÃ¶rselleÅŸtirilmesi.
4. **Modelleme**: Veri setinin Ã¶zelliklerine gÃ¶re uygun modelin seÃ§ilmesi ve oluÅŸturulmasÄ±.
5. **SonuÃ§larÄ±n YorumlanmasÄ±**: Analiz edilen verilerden elde edilen bilgilerin deÄŸerlendirilmesi ve karar sÃ¼reÃ§lerine entegre edilmesi.

Bu adÄ±mlar, veri bilimi projelerinin baÅŸarÄ±sÄ±nÄ± artÄ±rÄ±r.

---

### âœ… **Veri Bilimi ve Ä°statistik ArasÄ±ndaki Farklar**

- **AmaÃ§**: Ä°statistik, genellikle veri kÃ¼mesine dayalÄ± hipotezleri test etmek iÃ§in kullanÄ±lÄ±rken, veri bilimi daha geniÅŸ bir perspektifle verilerden deÄŸerli bilgiler Ã§Ä±karma sÃ¼recine odaklanÄ±r.
- **Veri TÃ¼rleri**: Ä°statistik Ã§oÄŸunlukla yapÄ±landÄ±rÄ±lmÄ±ÅŸ verilerle Ã§alÄ±ÅŸÄ±rken, veri bilimi hem yapÄ±landÄ±rÄ±lmÄ±ÅŸ hem de yapÄ±landÄ±rÄ±lmamÄ±ÅŸ verilerle ilgilenir.
- **AraÃ§lar**: Ä°statistiksel analiz iÃ§in genellikle R veya SPSS gibi yazÄ±lÄ±mlar kullanÄ±lÄ±rken, veri biliminde Python, R ve SQL gibi programlama dilleri tercih edilir.

---

## ğŸ“Œ 12.2 Veri Toplama ve Veri KaynaklarÄ±

Veri toplama, veri bilimi sÃ¼recinin baÅŸlangÄ±Ã§ noktasÄ±dÄ±r. DoÄŸru veri toplama yÃ¶ntemleri, analiz sonuÃ§larÄ±nÄ±n gÃ¼venilirliÄŸini artÄ±rÄ±r.

### âœ… **Veri Toplama YÃ¶ntemleri**

#### ğŸ“‹ **Anketler ve Formlar**
Anketler, belirli bir grubun gÃ¶rÃ¼ÅŸlerini toplamak iÃ§in kullanÄ±lan yaygÄ±n bir yÃ¶ntemdir. Hedefli verilerin toplanmasÄ±nÄ± saÄŸlar. 

- **PÃ¼f NoktasÄ±**: Anketlerin kÄ±sa, anlaÅŸÄ±lÄ±r ve hedefe yÃ¶nelik olmasÄ± Ã¶nemlidir. KatÄ±lÄ±mcÄ±larÄ±n motivasyonunu artÄ±rmak iÃ§in bazÄ± Ã¶dÃ¼ller de sunulabilir.

#### ğŸŒ **Web KazÄ±ma (Web Scraping)**
Web kazÄ±ma, internette bulunan verilerin programatik olarak toplanmasÄ±nÄ± saÄŸlar. HTML yapÄ±sÄ±nÄ± analiz ederek verileri Ã§Ä±karÄ±r.

##### Ã–rnek: Python ile web kazÄ±ma
```python
import requests  # HTTP istekleri yapmak iÃ§in
from bs4 import BeautifulSoup  # HTML dÃ¶kÃ¼manlarÄ±nÄ± analiz etmek iÃ§in

# Web sayfasÄ±nÄ± al
response = requests.get("http://acodex.com.tr")  # Belirtilen URL'ye istek gÃ¶nder

# HTML iÃ§eriÄŸini Ã§Ã¶zÃ¼mleme
soup = BeautifulSoup(response.text, 'html.parser')  # Gelen HTML yanÄ±tÄ±nÄ± parse et

# BaÅŸlÄ±klarÄ± Ã§Ä±kar
for title in soup.find_all('h1'):  # TÃ¼m 'h1' etiketlerini bul
    print(title.text)  # BaÅŸlÄ±klarÄ±n metin iÃ§eriklerini yazdÄ±r
```
Bu kod, belirtilen web sayfasÄ±ndaki tÃ¼m baÅŸlÄ±klarÄ± alÄ±r. KullanÄ±m alanlarÄ± arasÄ±nda piyasa analizi, iÃ§erik toplama ve araÅŸtÄ±rmalar yer alÄ±r.

- **PÃ¼f NoktasÄ±**: Web kazÄ±ma yaparken sitenin kullanÄ±m ÅŸartlarÄ±na dikkat edin ve aÅŸÄ±rÄ± yÃ¼klememeye Ã¶zen gÃ¶sterin.

#### ğŸ”— **API'ler ve Veri TabanlarÄ±**
API'ler, farklÄ± sistemler arasÄ±nda veri paylaÅŸÄ±mÄ±nÄ± saÄŸlayan arayÃ¼zlerdir. Veri tabanlarÄ± ise yapÄ±landÄ±rÄ±lmÄ±ÅŸ verilerin saklandÄ±ÄŸÄ± sistemlerdir.

##### Ã–rnek: Twitter API ile veri toplama
```python
import tweepy  # Twitter API ile etkileÅŸim iÃ§in

# Twitter API ile kimlik doÄŸrulama
auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)
api = tweepy.API(auth)  # API nesnesini oluÅŸtur

# KullanÄ±cÄ±nÄ±n tweetlerini al
tweets = api.user_timeline(screen_name="acodex.official", count=10)  # Belirtilen kullanÄ±cÄ±dan son 10 tweeti al (Tweeter hesabÄ±m yok :))

# Tweetleri yazdÄ±r
for tweet in tweets:  
    print(tweet.text)  # Her bir tweetin metin iÃ§eriÄŸini yazdÄ±r
```
Bu Ã¶rnek, Twitter API'si kullanarak bir kullanÄ±cÄ±nÄ±n en son tweetlerini toplar. API'ler, verilerin sistematik ve hÄ±zlÄ± bir ÅŸekilde alÄ±nmasÄ±nÄ± saÄŸlar.

- **PÃ¼f NoktasÄ±**: API belgelerini dikkatlice inceleyin ve kullanÄ±labilir sÄ±nÄ±rlarÄ± (rate limits) kontrol edin.

---

### âœ… **Veri KaynaklarÄ± ve Veri TÃ¼rleri**

#### ğŸ—‚ï¸ **YapÄ±sal ve YapÄ±sal Olmayan Veriler**
- **YapÄ±sal Veriler**: Tablo formatÄ±nda dÃ¼zenlenmiÅŸ, genellikle SQL veritabanlarÄ±nda bulunan verilerdir. Analizi kolaydÄ±r.
- **YapÄ±sal Olmayan Veriler**: Metin dosyalarÄ±, e-postalar ve sosyal medya gÃ¶nderileri gibi dÃ¼zenlenmemiÅŸ veri tÃ¼rleridir. Analiz iÃ§in Ã¶n iÅŸleme gerek duyabilir.

#### ğŸ“„ **Ä°Ã§erik ve Meta Veriler**
- **Ä°Ã§erik Verileri**: GerÃ§ek bilgiler veya veriler.
- **Meta Veriler**: Verilerin nasÄ±l toplandÄ±ÄŸÄ±, formatÄ± ve kaynaÄŸÄ± gibi bilgileri iÃ§eren verilerdir. Ã–rneÄŸin, bir resmin boyutlarÄ± veya oluÅŸturulma tarihi.

---


## ğŸ“Œ 12.3 Veri Temizleme ve Ã–n Ä°ÅŸleme

Veri temizleme, veri analizi veya makine Ã¶ÄŸrenimi sÃ¼reÃ§lerinin en Ã¶nemli adÄ±mlarÄ±ndan biridir. HatalÄ± veya eksik veriler, modelin doÄŸruluÄŸunu olumsuz yÃ¶nde etkileyebilir.

### âœ… **Veri Temizleme AdÄ±mlarÄ±**

#### âš ï¸ **Eksik Veri Ä°ÅŸleme**
Veri setinde eksik deÄŸerlerin bulunmasÄ± yaygÄ±n bir durumdur. Bu eksik veriler, bir veri kÃ¼mesinin analiz edilmesini zorlaÅŸtÄ±rabilir. 

##### Eksik Verilerle BaÅŸ Etme YÃ¶ntemleri
1. **SatÄ±r veya SÃ¼tun Silme**: 
   - Eksik verilerin bulunduÄŸu satÄ±r veya sÃ¼tunlarÄ± tamamen kaldÄ±rmak. 
   - KullanÄ±mÄ±: KÃ¼Ã§Ã¼k veri setlerinde etkili olabilir ama bÃ¼yÃ¼k veri setlerinde Ã¶nemli verilerin kaybÄ±na neden olabilir.
   ```python
   df.dropna()  # TÃ¼m eksik deÄŸerlere sahip satÄ±rlarÄ± kaldÄ±rÄ±r.
   ```

2. **Eksik Verileri Doldurma**:
   - OrtalamasÄ±nÄ±, medyanÄ±nÄ± veya modunu kullanarak eksik verileri doldurmak. 
   - KullanÄ±mÄ±: Bilgiyi kaybetmemek iÃ§in ideal bir yaklaÅŸÄ±mdÄ±r.
   ```python
   df['column_name'].fillna(df['column_name'].mean(), inplace=True)  # Ortalama ile doldurma
   ```

3. **Tahmin Etme**:
   - Makine Ã¶ÄŸrenimi algoritmalarÄ± kullanarak eksik verileri tahmin etme. 
   - KullanÄ±mÄ±: Bu yÃ¶ntem, eksik verilerin Ã¶nemli olduÄŸu durumlarda kullanÄ±lÄ±r.
   ```python
   from sklearn.impute import SimpleImputer
   imputer = SimpleImputer(strategy='mean')
   df['column_name'] = imputer.fit_transform(df[['column_name']])
   ```

#### ğŸš¨ **HatalÄ± Veri ve Anomaliler**
Veri setinde yer alan hatalÄ± veriler veya aÅŸÄ±rÄ± deÄŸerler (outliers), analizlerin gÃ¼venilirliÄŸini etkileyebilir. Bu veriler, Ã§oÄŸu zaman yanlÄ±ÅŸ Ã¶lÃ§Ã¼m veya veri giriÅŸi sonucunda oluÅŸur.

##### HatalÄ± Verilerin Belirlenmesi
- **Ä°statistiksel Analiz**: Verilerin temel istatistikleri (ortalama, standart sapma) ile normal dÄ±ÅŸÄ± deÄŸerleri belirleme.
- **GÃ¶rselleÅŸtirme**: Box plot veya scatter plot gibi grafikler kullanarak aÅŸÄ±rÄ± deÄŸerleri gÃ¶zlemleme.

##### HatalÄ± Verilerin DÃ¼zeltme YÃ¶ntemleri
1. **DÃ¼zeltme**: HatalÄ± veriyi mantÄ±klÄ± bir deÄŸerle deÄŸiÅŸtirme.
   ```python
   df.loc[df['column_name'] > 100, 'column_name'] = 100  # AÅŸÄ±rÄ± deÄŸeri dÃ¼zeltiyor.
   ```

2. **Silme**: AÅŸÄ±rÄ± deÄŸerleri iÃ§eren satÄ±rlarÄ±n silinmesi.
   ```python
   df = df[df['column_name'] <= 100]  # 100'den bÃ¼yÃ¼k deÄŸerleri kaldÄ±rma.
   ```

#### âœ… **Veri DÃ¶nÃ¼ÅŸÃ¼m ve Normalizasyon**
Veri dÃ¶nÃ¼ÅŸÃ¼mÃ¼, verilerin analiz ve modelleme sÃ¼reÃ§leri iÃ§in uygun hale getirilmesi iÅŸlemidir. Normalizasyon ise verileri belirli bir aralÄ±ÄŸa Ã§ekmek anlamÄ±na gelir.

- **Normalizasyon**: Ã–zellikle makine Ã¶ÄŸrenimi algoritmalarÄ±nda verilerin aynÄ± Ã¶lÃ§eÄŸe Ã§ekilmesi gerektiÄŸinde kullanÄ±lÄ±r.
```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
df['normalized_column'] = scaler.fit_transform(df[['column_name']])
```
Bu iÅŸlem, tÃ¼m deÄŸerleri 0 ile 1 arasÄ±nda bir aralÄ±ÄŸa Ã§eker.

- **Standardizasyon**: Verilerin ortalamasÄ±nÄ± 0 ve standart sapmasÄ±nÄ± 1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rme.
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df['standardized_column'] = scaler.fit_transform(df[['column_name']])
```

#### âœ… **Ã–zellik SeÃ§imi ve Ã–zellik MÃ¼hendisliÄŸi**
Veri setindeki en Ã¶nemli Ã¶zelliklerin belirlenmesi, modelin baÅŸarÄ±sÄ±nÄ± artÄ±rabilir. Ã–zellik mÃ¼hendisliÄŸi, verilerden yeni Ã¶zellikler oluÅŸturmayÄ± iÃ§erir.

- **Ã–zellik SeÃ§imi**: En Ã¶nemli Ã¶zellikleri belirlemek iÃ§in teknikler kullanma (Ã¶rneÄŸin, karar aÄŸaÃ§larÄ±, korelasyon matrisleri).
- **Ã–zellik MÃ¼hendisliÄŸi**: Mevcut verilerden yeni bilgiler elde etme.
```python
df['income_per_age'] = df['income'] / df['age']  # Yeni Ã¶zellik oluÅŸturma
```

#### âœ… **Veri Tipleri ve DÃ¶nÃ¼ÅŸÃ¼mleri**
Veri tÃ¼rleri, veri iÅŸleme ve analizde kritik bir rol oynar. Pythonâ€™da yaygÄ±n veri tÃ¼rleri ÅŸunlardÄ±r:
- **Integer**: Tam sayÄ±lar
- **Float**: Kesirli sayÄ±lar
- **String**: Metin verileri
- **Boolean**: True/False deÄŸerleri

Veri tÃ¼rlerini deÄŸiÅŸtirmek, analitik sÃ¼reÃ§te esneklik saÄŸlar.
```python
df['column_name'] = df['column_name'].astype(int)  # Veri tipini tam sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rme
```

---

## ğŸ“Œ 12.4 Veri GÃ¶rselleÅŸtirme

Veri gÃ¶rselleÅŸtirme, karmaÅŸÄ±k verileri gÃ¶rsel hale getirerek daha anlaÅŸÄ±lÄ±r hale getirir. Ä°yi bir gÃ¶rselleÅŸtirme, verilerdeki desenleri, eÄŸilimleri ve anormallikleri hÄ±zlÄ±ca anlamayÄ± saÄŸlar.

### âœ… **Veri GÃ¶rselleÅŸtirmenin Ã–nemi**
- **HÄ±zlÄ± AnlayÄ±ÅŸ**: Veriler gÃ¶rsel olarak sunulduÄŸunda, karmaÅŸÄ±k iliÅŸkileri ve eÄŸilimleri daha hÄ±zlÄ± kavrayabiliriz.
- **Ä°letiÅŸim**: Verileri baÅŸkalarÄ±na anlatmanÄ±n en etkili yolu gÃ¶rselleÅŸtirmelerdir.
- **HatalarÄ±n Tespiti**: GÃ¶rselleÅŸtirme, verilerdeki hatalarÄ± veya anomalileri gÃ¶zle gÃ¶rmek iÃ§in yararlÄ±dÄ±r.

### âœ… **GÃ¶rselleÅŸtirme AraÃ§larÄ± ve KÃ¼tÃ¼phaneleri**

#### ğŸ“Š **Matplotlib**
Pythonâ€™un en popÃ¼ler gÃ¶rselleÅŸtirme kÃ¼tÃ¼phanesidir. Ã‡izgi grafikleri, Ã§ubuk grafikleri ve histogramlar gibi temel grafik tÃ¼rleri oluÅŸturmak iÃ§in kullanÄ±lÄ±r.

##### Ã–rnek: Basit Ã‡izgi GrafiÄŸi
```python
import matplotlib.pyplot as plt

x = [1, 2, 3, 4, 5]
y = [10, 20, 25, 30, 35]

plt.plot(x, y, color='blue', marker='o', linestyle='-', linewidth=2)  # Ã‡izgi grafiÄŸi
plt.title("Basit Ã‡izgi GrafiÄŸi")
plt.xlabel("X Ekseni")
plt.ylabel("Y Ekseni")
plt.grid(True)  # Izgara Ã§izgilerini aÃ§ma
plt.show()
```
Bu kod, x ve y deÄŸerleri ile basit bir Ã§izgi grafiÄŸi oluÅŸturur. Grafikte kullanÄ±lan `marker` ve `linestyle` gibi parametrelerle grafik estetik olarak iyileÅŸtirilir.

#### ğŸ“ˆ **Seaborn**
Seaborn, Matplotlib Ã¼zerine inÅŸa edilmiÅŸ bir kÃ¼tÃ¼phanedir ve daha estetik ve karmaÅŸÄ±k grafikler oluÅŸturmayÄ± saÄŸlar.

##### Ã–rnek: Seaborn ile DaÄŸÄ±lÄ±m GrafiÄŸi
```python
import seaborn as sns
import pandas as pd

data = {'age': [25, 32, 47, 54, 23],
        'income': [50000, 60000, 75000, 80000, 45000]}
df = pd.DataFrame(data)

sns.scatterplot(x='age', y='income', data=df)
plt.title("YaÅŸ ve Gelir DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("YaÅŸ")
plt.ylabel("Gelir")
plt.show()
```
Bu grafik, yaÅŸ ve gelir arasÄ±ndaki iliÅŸkiyi gÃ¶rselleÅŸtirir. Seaborn, estetik ayarlarÄ± otomatik olarak yaparak daha ÅŸÄ±k gÃ¶rseller oluÅŸturur.

#### ğŸ“Š **Plotly**
Dinamik ve etkileÅŸimli grafikler oluÅŸturmak iÃ§in kullanÄ±lan bir kÃ¼tÃ¼phanedir. Web tabanlÄ± uygulamalar iÃ§in ideal bir seÃ§imdir.

##### Ã–rnek: Plotly ile Ã‡izgi GrafiÄŸi
```python
import plotly.express as px

data = {'Year': [2020, 2021, 2022],
        'Sales': [150, 200, 300]}
df = pd.DataFrame(data)

fig = px.line(df, x='Year', y='Sales', title='YÄ±llÄ±k SatÄ±ÅŸlar')
fig.show()  # EtkileÅŸimli grafik gÃ¶sterimi
```
Bu kod, yÄ±llÄ±k satÄ±ÅŸlarÄ± iÃ§eren etkileÅŸimli bir Ã§izgi grafiÄŸi oluÅŸturur.

### âœ… **Temel Grafik TÃ¼rleri**

#### ğŸ“Š **Histogramlar**
Veri daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir ve veri setinin nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ±nÄ± anlamaya yardÄ±mcÄ± olur. Histogramlar, belirli bir aralÄ±kta kaÃ§ adet veri noktasÄ± olduÄŸunu gÃ¶sterir.

##### Ã–rnek: Histogram OluÅŸturma
```python
import numpy as

 np

data = np.random.randn(1000)  # Normal daÄŸÄ±lÄ±mlÄ± rastgele veriler
plt.hist(data, bins=30, alpha=0.7, color='blue')  # Histogram
plt.title("Histogram")
plt.xlabel("DeÄŸerler")
plt.ylabel("Frekans")
plt.grid(True)  # Izgara Ã§izgileri
plt.show()
```
Bu histogram, normal daÄŸÄ±lÄ±ma sahip 1000 veri noktasÄ±nÄ±n daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir.

#### ğŸ“ˆ **Ã‡izgi Grafikler**
Zamansal verilerin deÄŸiÅŸimini gÃ¶stermek iÃ§in kullanÄ±lÄ±r. Verilerin sÃ¼rekli deÄŸiÅŸimini anlamak iÃ§in idealdir.

#### ğŸ“Š **DaÄŸÄ±lÄ±m Grafikleri (Scatter Plot)**
Ä°ki deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi gÃ¶sterir. AÅŸÄ±rÄ± deÄŸerler ve trendleri tespit etmek iÃ§in kullanÄ±lÄ±r.

### ğŸ“Š **Pasta Grafikler**
Kategorik verilerin yÃ¼zdelerini gÃ¶stermek iÃ§in kullanÄ±lÄ±r. Ancak, Ã§ok fazla kategori olduÄŸunda yanÄ±ltÄ±cÄ± olabilir, bu yÃ¼zden dikkatli kullanÄ±lmalÄ±dÄ±r.

##### Ã–rnek: Pasta GrafiÄŸi OluÅŸturma
```python
labels = ['A', 'B', 'C', 'D']
sizes = [15, 30, 45, 10]

plt.pie(sizes, labels=labels, autopct='%1.1f%%')  # Pasta grafiÄŸi
plt.title("Pasta GrafiÄŸi")
plt.axis('equal')  # EÅŸit eksen oranlarÄ±
plt.show()
```
Bu kod, dÃ¶rt kategori arasÄ±ndaki yÃ¼zdeleri gÃ¶steren bir pasta grafiÄŸi oluÅŸturur.

#### ğŸ“Š **Ä°leri DÃ¼zey GÃ¶rselleÅŸtirme Teknikleri**
- **Heatmaps**: Veri yoÄŸunluÄŸunu gÃ¶steren renkli matrislerdir. Ã–zellikle korelasyon matrisleri iÃ§in yararlÄ±dÄ±r.
- **Box Plots**: Verilerin medyanÄ±nÄ±, Ã§eyreklerini ve aÅŸÄ±rÄ± deÄŸerlerini gÃ¶rselleÅŸtirmek iÃ§in kullanÄ±lÄ±r.
- **Violin Plots**: DaÄŸÄ±lÄ±mÄ±n yoÄŸunluÄŸunu ve medyanÄ±nÄ± aynÄ± anda gÃ¶sterir, verinin daÄŸÄ±lÄ±mÄ±na dair daha fazla bilgi sunar.

---


## ğŸ“Œ 12.5 Ä°statistiksel Analiz

Ä°statistiksel analiz, veri kÃ¼mesinin Ã¶zelliklerini anlamak ve karar vermek iÃ§in veri setlerinden bilgi Ã§Ä±karma sÃ¼recidir. Bu sÃ¼reÃ§te, temel istatistik kavramlarÄ±ndan istatistiksel daÄŸÄ±lÄ±mlara kadar birÃ§ok Ã¶nemli kavram ele alÄ±nÄ±r.

### âœ… **Temel Ä°statistik KavramlarÄ±**

#### âš–ï¸ **Ortalama, Medyan, Mod**
- **Ortalama**: Veri kÃ¼mesindeki tÃ¼m deÄŸerlerin toplamÄ±nÄ±n, deÄŸer sayÄ±sÄ±na bÃ¶lÃ¼nmesiyle elde edilen deÄŸerdir.
  ```python
  import numpy as np

  data = [10, 20, 30, 40, 50]
  mean = np.mean(data)  # Ortalama hesaplama
  print("Ortalama:", mean)  # Ã‡Ä±ktÄ±: Ortalama: 30.0
  ```

- **Medyan**: Veri kÃ¼mesinin ortasÄ±nda yer alan deÄŸerdir. Veri sÄ±ralandÄ±ÄŸÄ±nda, ortada kalan deÄŸeri temsil eder.
  ```python
  median = np.median(data)  # Medyan hesaplama
  print("Medyan:", median)  # Ã‡Ä±ktÄ±: Medyan: 30.0
  ```

- **Mod**: En sÄ±k tekrar eden deÄŸerdir. Birden fazla modlu veri setleri de olabilir.
  ```python
  from scipy import stats

  mode = stats.mode(data)  # Mod hesaplama
  print("Mod:", mode.mode[0])  # Ã‡Ä±ktÄ±: Mod: 10
  ```

#### ğŸ“Š **Varyans ve Standart Sapma**
- **Varyans**: Verilerin ortalamadan ne kadar uzaklaÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steren bir Ã¶lÃ§Ã¼dÃ¼r. YÃ¼ksek varyans, verilerin geniÅŸ bir aralÄ±kta daÄŸÄ±ldÄ±ÄŸÄ±nÄ± gÃ¶sterir.
  ```python
  variance = np.var(data)  # Varyans hesaplama
  print("Varyans:", variance)  # Ã‡Ä±ktÄ±: Varyans: 200.0
  ```

- **Standart Sapma**: VaryansÄ±n karekÃ¶kÃ¼dÃ¼r ve verinin ortalamadan ne kadar sapma gÃ¶sterdiÄŸini Ã¶lÃ§er.
  ```python
  std_deviation = np.std(data)  # Standart sapma hesaplama
  print("Standart Sapma:", std_deviation)  # Ã‡Ä±ktÄ±: Standart Sapma: 14.142135623730951
  ```

### âœ… **Ä°statistiksel DaÄŸÄ±lÄ±mlar**

Ä°statistiksel daÄŸÄ±lÄ±mlar, veri kÃ¼mesinin daÄŸÄ±lÄ±mÄ±nÄ± ve olasÄ±lÄ±klarÄ±nÄ± anlamaya yardÄ±mcÄ± olur.

#### ğŸ“ˆ **Normal DaÄŸÄ±lÄ±m**
Normal daÄŸÄ±lÄ±m, en yaygÄ±n daÄŸÄ±lÄ±m tÃ¼rlerinden biridir. Ã‡an ÅŸeklinde bir daÄŸÄ±lÄ±m gÃ¶sterir ve birÃ§ok doÄŸal olayÄ± modellemek iÃ§in kullanÄ±lÄ±r.

#### ğŸŸ  **Binom DaÄŸÄ±lÄ±mÄ±**
BaÅŸarÄ± ve baÅŸarÄ±sÄ±zlÄ±k gibi iki sonucun olduÄŸu deneylerde (Ã¶rneÄŸin, bir paranÄ±n atÄ±lmasÄ±) kullanÄ±lÄ±r. Binom daÄŸÄ±lÄ±mÄ±, belirli bir sayÄ±da baÅŸarÄ± elde etme olasÄ±lÄ±ÄŸÄ±nÄ± hesaplar.

#### ğŸ”µ **Poisson DaÄŸÄ±lÄ±mÄ±**
Belirli bir zaman diliminde veya alanda belirli bir olayÄ±n gerÃ§ekleÅŸme olasÄ±lÄ±ÄŸÄ±nÄ± hesaplamak iÃ§in kullanÄ±lÄ±r (Ã¶rneÄŸin, bir dÃ¼kkanda belirli bir sÃ¼re iÃ§inde gelen mÃ¼ÅŸteri sayÄ±sÄ±).

### âœ… **Hipotez Testleri ve P-DeÄŸerleri**

Hipotez testleri, verilerin anlamlÄ±lÄ±ÄŸÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lÄ±r. Bir hipotez, genellikle iki tÃ¼r olur: null (H0) ve alternatif (H1) hipotezler.

#### ğŸ“ **T-Testi**
Ä°ki grup arasÄ±ndaki ortalama farkÄ±nÄ± test eder. Ã–rneÄŸin, iki farklÄ± ilaÃ§ grubunun etkilerinin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±.
```python
from scipy import stats

group1 = [20, 21, 19, 24, 22]
group2 = [30, 31, 29, 28, 32]
t_stat, p_value = stats.ttest_ind(group1, group2)  # Ä°ki grup iÃ§in t-testi
print("T-Ä°statistiÄŸi:", t_stat, "p-deÄŸeri:", p_value)
```

#### ğŸ“Š **Ki-Kare Testi**
Kategorik verilerin baÄŸÄ±msÄ±zlÄ±ÄŸÄ±nÄ± test etmek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, bir Ã¼rÃ¼nÃ¼n tercih edilme oranÄ±nÄ±n cinsiyete gÃ¶re deÄŸiÅŸip deÄŸiÅŸmediÄŸini test etmek.
```python
contingency_table = [[10, 20], [20, 30]]
chi2_stat, p_value, dof, expected = stats.chi2_contingency(contingency_table)
print("Ki-Kare Ä°statistiÄŸi:", chi2_stat, "p-deÄŸeri:", p_value)
```

#### ğŸ“ˆ **ANOVA (Varyans Analizi)**
ÃœÃ§ veya daha fazla grubun ortalamalarÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, Ã¼Ã§ farklÄ± Ã¼rÃ¼nÃ¼n satÄ±ÅŸlarÄ±nÄ±n karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±.
```python
group1 = [20, 21, 19]
group2 = [30, 31, 29]
group3 = [40, 41, 39]
f_stat, p_value = stats.f_oneway(group1, group2, group3)  # ANOVA testi
print("F-Ä°statistiÄŸi:", f_stat, "p-deÄŸeri:", p_value)
```

---

## ğŸ“Œ 12.6 Veri Analizi ve Modelleme

Veri analizi, verileri anlamak ve iÃ§gÃ¶rÃ¼ elde etmek iÃ§in gerÃ§ekleÅŸtirilen bir sÃ¼reÃ§tir. Bu sÃ¼reÃ§te Ã§eÅŸitli yÃ¶ntemler ve modeller kullanÄ±lÄ±r.

### âœ… **Veri Analizinin Temel YÃ¶ntemleri**
Veri analizi, gÃ¶zlemleme, aÃ§Ä±klayÄ±cÄ± istatistik ve modelleme gibi Ã§eÅŸitli yÃ¶ntemleri iÃ§erir. Analiz sÃ¼reci, verilerin toplanmasÄ±ndan baÅŸlar ve iÃ§gÃ¶rÃ¼ elde edilmesiyle sonuÃ§lanÄ±r.

### âœ… **Regresyon Analizi**
Veri analizi sÃ¼recinde, baÄŸÄ±mlÄ± ve baÄŸÄ±msÄ±z deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi incelemek iÃ§in regresyon analizi kullanÄ±lÄ±r.

#### ğŸ“‰ **DoÄŸrusal Regresyon**
Bir baÄŸÄ±msÄ±z deÄŸiÅŸken ile bir baÄŸÄ±mlÄ± deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi modellemek iÃ§in kullanÄ±lÄ±r. DoÄŸrusal bir iliÅŸki varsayÄ±ldÄ±ÄŸÄ±nda basit doÄŸrusal regresyon kullanÄ±lÄ±r.
```python
from sklearn.linear_model import LinearRegression

X = [[1], [2], [3], [4]]  # BaÄŸÄ±msÄ±z deÄŸiÅŸken
y = [1, 3, 2, 3]  # BaÄŸÄ±mlÄ± deÄŸiÅŸken

model = LinearRegression()
model.fit(X, y)  # Modeli eÄŸitme
print("KatsayÄ±:", model.coef_, "Intercept:", model.intercept_)
```

#### ğŸ“Š **Ã‡oklu Regresyon**
Birden fazla baÄŸÄ±msÄ±z deÄŸiÅŸkenin bir baÄŸÄ±mlÄ± deÄŸiÅŸken Ã¼zerindeki etkisini modellemek iÃ§in kullanÄ±lÄ±r. 
```python
import pandas as pd

data = pd.DataFrame({
    'X1': [1, 2, 3, 4],
    'X2': [2, 3, 4, 5],
    'y': [1, 3, 2, 3]
})

model = LinearRegression()
model.fit(data[['X1', 'X2']], data['y'])  # Ã‡oklu regresyon modeli
print("KatsayÄ±lar:", model.coef_)
```

### âœ… **SÄ±nÄ±flandÄ±rma Analizi**
SÄ±nÄ±flandÄ±rma analizi, verileri belirli sÄ±nÄ±flara ayÄ±rmak iÃ§in kullanÄ±lan bir tekniktir. 

### ğŸ” **Lojistik Regresyon**
Ä°kili sonuÃ§lar (0 veya 1) Ã¼reten bir modeldir. Ã–rneÄŸin, bir e-posta mesajÄ±nÄ±n spam olup olmadÄ±ÄŸÄ±nÄ± sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lÄ±r.
```python
from sklearn.linear_model import LogisticRegression

X = [[0], [1], [2], [3]]
y = [0, 0, 1, 1]  # Ä°kili sÄ±nÄ±flar

model = LogisticRegression()
model.fit(X, y)  # Lojistik regresyon modeli
print("KatsayÄ±lar:", model.coef_)
```

#### ğŸŒ³ **Karar AÄŸaÃ§larÄ±**
Veri setini aÄŸaÃ§ yapÄ±sÄ±nda sÄ±nÄ±flandÄ±rÄ±r. Her bir dal, bir karar noktasÄ±dÄ±r ve sonuca ulaÅŸmak iÃ§in izlenen yoldur.
```python
from sklearn.tree import DecisionTreeClassifier

X = [[0], [1], [2], [3]]
y = [0, 0, 1, 1]

model = DecisionTreeClassifier()
model.fit(X, y)  # Karar aÄŸaÃ§larÄ± modeli
```

#### ğŸš€ **Destek VektÃ¶r Makineleri (SVM)**
Veri noktalarÄ±nÄ± en iyi ayÄ±ran hiper dÃ¼zlemi bulmaya Ã§alÄ±ÅŸÄ±r. Ã–zellikle karmaÅŸÄ±k ve yÃ¼ksek boyutlu verilerde etkilidir.
```python
from sklearn import svm

X = [[0], [1], [2], [3]]
y = [0, 0, 1, 1]

model = svm.S

VC()
model.fit(X, y)  # SVM modeli
```

### âœ… **KÃ¼meleme ve Segmentasyon**
Verileri benzerliklerine gÃ¶re gruplandÄ±rma iÅŸlemidir. 

### ğŸ”µ **K-Means KÃ¼meleme**
Verileri k sayÄ±da kÃ¼meye ayÄ±rmak iÃ§in kullanÄ±lÄ±r. Her bir kÃ¼me, veri noktalarÄ±nÄ±n ortalamasÄ± ile temsil edilir.
```python
from sklearn.cluster import KMeans

data = [[1, 2], [1, 4], [1, 0], [4, 2], [4, 0]]
kmeans = KMeans(n_clusters=2, random_state=0).fit(data)  # K-Means kÃ¼meleme
print("KÃ¼me merkezleri:", kmeans.cluster_centers_)
```

#### ğŸ“Š **Hierarchical Clustering**
Veri kÃ¼mesinin hiyerarÅŸik bir yapÄ±da gruplandÄ±rÄ±lmasÄ±nÄ± saÄŸlar. AÄŸaÃ§ yapÄ±sÄ± olarak gÃ¶rselleÅŸtirilebilir.

### âœ… **Zaman Serisi Analizi**
Zaman serisi analizi, verilerin zaman iÃ§indeki deÄŸiÅŸimini incelemek iÃ§in kullanÄ±lÄ±r. Ã–zellikle finansal verilerde, hava durumu tahminlerinde ve birÃ§ok farklÄ± alanda kullanÄ±lÄ±r.

Zaman serisi analizi, verilerin zaman dilimlerine gÃ¶re dÃ¼zenlenmesini ve trendlerin, mevsimselliÄŸin ve dÃ¶ngÃ¼lerin incelenmesini iÃ§erir.

---


## ğŸ“Œ 12.7 Makine Ã–ÄŸrenmesi ve Veri Bilimi

Makine Ã¶ÄŸrenmesi, bilgisayar sistemlerinin verilerden otomatik olarak Ã¶ÄŸrenme ve tahminlerde bulunma yeteneÄŸidir. Veri bilimi, makine Ã¶ÄŸrenmesini uygulamak ve veri analizi yapmak iÃ§in gerekli araÃ§lar ve yÃ¶ntemler saÄŸlar.

### âœ… **Makine Ã–ÄŸrenmesi Temelleri**

Makine Ã¶ÄŸrenmesi, belirli bir gÃ¶rev iÃ§in algoritmalar geliÅŸtirmek amacÄ±yla verilere dayalÄ± olarak Ã¶ÄŸrenme yÃ¶ntemlerini iÃ§erir. Temel bileÅŸenleri ÅŸunlardÄ±r:

- **Veri**: Modelin eÄŸitilmesi iÃ§in kullanÄ±lan bilgi kÃ¼mesi.
- **Algoritma**: Verilerden Ã¶ÄŸrenme sÃ¼recini yÃ¶neten matematiksel yÃ¶ntem.
- **Model**: AlgoritmanÄ±n, verilerden Ã¶ÄŸrendiÄŸi ve tahmin yapmak iÃ§in kullandÄ±ÄŸÄ± yapÄ±.

Makine Ã¶ÄŸrenmesi genellikle iki ana gruba ayrÄ±lÄ±r: denetimli ve denetimsiz Ã¶ÄŸrenme.

#### ğŸ” **Denetimli Ã–ÄŸrenme**

Denetimli Ã¶ÄŸrenme, etiketlenmiÅŸ veriler kullanÄ±larak modelin eÄŸitilmesi anlamÄ±na gelir. Bu tÃ¼r Ã¶ÄŸrenme, modelin belirli bir girdi ile ona karÅŸÄ±lÄ±k gelen bir Ã§Ä±ktÄ±yÄ± Ã¶ÄŸrenmesini saÄŸlar. Ã–rneÄŸin, bir e-postanÄ±n spam olup olmadÄ±ÄŸÄ±nÄ± belirlemek iÃ§in etiketlenmiÅŸ veriler kullanÄ±lÄ±r. Temel adÄ±mlar:

1. **Veri Toplama**: EÄŸitim iÃ§in gerekli verilerin toplanmasÄ±.
2. **Ã–znitelik SeÃ§imi**: Modelin daha iyi Ã¶ÄŸrenmesini saÄŸlamak iÃ§in Ã¶nemli Ã¶zelliklerin seÃ§ilmesi.
3. **Model EÄŸitimi**: SeÃ§ilen verilerle modelin eÄŸitilmesi.

```python
from sklearn.linear_model import LogisticRegression

# Ã–zellikler ve etiketler
X = [[1, 0], [0, 1], [1, 1], [0, 0]]  # Ã–zellikler
y = [1, 0, 1, 0]  # Etiketler (1: spam, 0: deÄŸil)

# Modelin oluÅŸturulmasÄ± ve eÄŸitilmesi
model = LogisticRegression()
model.fit(X, y)
```
YukarÄ±daki kod, iki Ã¶zellik ile spam olup olmadÄ±ÄŸÄ±nÄ± belirleyen basit bir lojistik regresyon modelinin nasÄ±l eÄŸitileceÄŸini gÃ¶sterir. Ã–zellikler ve etiketler kullanÄ±larak model eÄŸitildiÄŸinde, model yeni verilere tahmin yapma yeteneÄŸine sahip olur.

#### ğŸ” **Denetimsiz Ã–ÄŸrenme**

Denetimsiz Ã¶ÄŸrenme, etiketlenmemiÅŸ veriler Ã¼zerinde modelin Ã§alÄ±ÅŸtÄ±ÄŸÄ± ve iÃ§gÃ¶rÃ¼ler elde etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ± bir yÃ¶ntemdir. Ã–rneÄŸin, K-means algoritmasÄ±, benzer Ã¶zelliklere sahip verileri gruplamak iÃ§in kullanÄ±lÄ±r. Temel adÄ±mlar:

1. **Veri Toplama**: EtiketlenmemiÅŸ verilerin toplanmasÄ±.
2. **Model SeÃ§imi**: Veri kÃ¼mesine uygun bir algoritmanÄ±n seÃ§ilmesi.
3. **Model EÄŸitimi**: Modelin veriler Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±lmasÄ±.

```python
from sklearn.cluster import KMeans

# EtiketlenmemiÅŸ veri kÃ¼mesi
data = [[1, 2], [1, 4], [1, 0], [4, 2], [4, 0]]

# K-means ile kÃ¼meleme
kmeans = KMeans(n_clusters=2, random_state=0).fit(data)
print("KÃ¼me merkezleri:", kmeans.cluster_centers_)
```
Bu kod, K-means algoritmasÄ± ile verileri iki kÃ¼meye ayÄ±rÄ±r ve her kÃ¼menin merkezini hesaplar.

### âœ… **Model SeÃ§imi ve DeÄŸerlendirme**

Model seÃ§imi, en uygun algoritmanÄ±n belirlenmesi sÃ¼recidir. Modeller genellikle ÅŸu metriklerle deÄŸerlendirilir:

- **DoÄŸruluk (Accuracy)**: DoÄŸru tahminlerin toplam tahminlere oranÄ±dÄ±r.
- **Hassasiyet (Precision)**: Pozitif tahminlerin gerÃ§ekte pozitif olanlarÄ±n oranÄ±dÄ±r.
- **DuyarlÄ±lÄ±k (Recall)**: GerÃ§ek pozitiflerin tahmin edilen pozitifler iÃ§indeki oranÄ±dÄ±r.

Modeli deÄŸerlendirmek iÃ§in k-fold Ã§apraz doÄŸrulama yÃ¶ntemi kullanÄ±labilir. Bu yÃ¶ntem, verileri k alt kÃ¼meye bÃ¶ler ve her alt kÃ¼me bir test seti olarak kullanÄ±lÄ±rken kalanlar eÄŸitim seti olarak kullanÄ±lÄ±r.

```python
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

# Modelin oluÅŸturulmasÄ±
model = RandomForestClassifier()
scores = cross_val_score(model, X, y, cv=5)  # 5 katlÄ± Ã§apraz doÄŸrulama
print("DoÄŸruluk SkorlarÄ±:", scores)
```
Bu kod, Random Forest modeli ile 5 katlÄ± Ã§apraz doÄŸrulama yaparak doÄŸruluk skorlarÄ±nÄ± hesaplar.

#### âœ… **Hiperparametre AyarÄ±**

Hiperparametreler, modelin eÄŸitim sÃ¼recini etkileyen parametrelerdir. Bu parametrelerin optimize edilmesi, model performansÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rabilir. Genellikle Grid Search veya Random Search kullanÄ±larak ayarlanÄ±r.

```python
from sklearn.model_selection import GridSearchCV

param_grid = {'n_estimators': [10, 50, 100]}
grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)
grid_search.fit(X, y)  # Hiperparametre ayarÄ±
print("En iyi parametreler:", grid_search.best_params_)
```
YukarÄ±daki kod, Random Forest modelinin en iyi hiperparametrelerini bulmak iÃ§in Grid Search kullanÄ±r.

### âœ… **Model PerformansÄ±nÄ± ArtÄ±rma**

Modelin performansÄ±nÄ± artÄ±rmak iÃ§in aÅŸaÄŸÄ±daki stratejiler kullanÄ±labilir:
- **Ã–zellik MÃ¼hendisliÄŸi**: Yeni Ã¶zellikler oluÅŸturmak veya mevcut Ã¶zellikleri dÃ¶nÃ¼ÅŸtÃ¼rmek.
- **Toplama YÃ¶ntemleri**: FarklÄ± modellerin bir araya getirilmesi (Ã¶rneÄŸin, bagging, boosting).
- **Daha Fazla Veri Kullanma**: Modelin eÄŸitilmesi iÃ§in daha fazla veri toplayarak genel performansÄ± artÄ±rmak.

---

## ğŸ“Œ 12.8 BÃ¼yÃ¼k Veri ve DaÄŸÄ±tÄ±k Sistemler

BÃ¼yÃ¼k veri, geleneksel veri iÅŸleme yazÄ±lÄ±mlarÄ±nÄ±n yÃ¶netemeyeceÄŸi bÃ¼yÃ¼klÃ¼kte ve karmaÅŸÄ±klÄ±kta verileri ifade eder. DaÄŸÄ±tÄ±k sistemler, bu verileri iÅŸlemek iÃ§in tasarlanmÄ±ÅŸtÄ±r.

### âœ… **BÃ¼yÃ¼k Veri KavramÄ± ve Ã–zellikleri**

BÃ¼yÃ¼k veri, genellikle 3V (Hacim, HÄ±z, Ã‡eÅŸitlilik) ile tanÄ±mlanÄ±r:
- **Hacim**: Veri miktarÄ±nÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼; terabyte ve petabyte dÃ¼zeyinde verileri iÃ§erir.
- **HÄ±z**: Verinin toplama, iÅŸleme ve analiz etme hÄ±zÄ±dÄ±r; anlÄ±k veri akÄ±ÅŸÄ± gerektiren uygulamalar.
- **Ã‡eÅŸitlilik**: FarklÄ± kaynaklardan ve formatlardan gelen verilerin Ã§eÅŸitliliÄŸidir (yapÄ±sal, yarÄ± yapÄ±sal, yapÄ±sal olmayan).

### âœ… **DaÄŸÄ±tÄ±k Sistemler ve AraÃ§lar**

DaÄŸÄ±tÄ±k sistemler, verilerin iÅŸlenmesi iÃ§in birden fazla bilgisayarÄ±n bir arada Ã§alÄ±ÅŸtÄ±ÄŸÄ± sistemlerdir. Bu sistemler, bÃ¼yÃ¼k veri kÃ¼melerinin iÅŸlenmesini kolaylaÅŸtÄ±rÄ±r.

#### ğŸ› ï¸ **Hadoop**
Hadoop, bÃ¼yÃ¼k veri iÅŸleme ve depolama iÃ§in aÃ§Ä±k kaynaklÄ± bir framework'tÃ¼r. AÅŸaÄŸÄ±daki bileÅŸenleri iÃ§erir:
- **HDFS (Hadoop Distributed File System)**: Verileri daÄŸÄ±tÄ±k bir ÅŸekilde depolar, bÃ¶ylece veriler birden fazla makinede saklanabilir.
- **MapReduce**: Verileri iÅŸlemek iÃ§in kullanÄ±lan bir programlama modeli; verileri paralel olarak iÅŸler.

Ã–rnek bir MapReduce uygulamasÄ±:
```python
# MapReduce uygulamasÄ± Ã¶rneÄŸi
from mrjob.job import MRJob

class MRWordCount(MRJob):
    def mapper(self, _, line):
        for word in line.split():
            yield word, 1

    def reducer(self, word, counts):
        yield word, sum(counts)

if __name__ == '__main__':
    MRWordCount.run()
```
Bu kod, metindeki kelime sayÄ±sÄ±nÄ± hesaplamak iÃ§in MapReduce yÃ¶ntemi kullanÄ±r.

#### âš¡ **Apache Spark**
Apache Spark, Hadoop'dan daha hÄ±zlÄ± veri iÅŸleme yeteneklerine sahip popÃ¼ler bir aÃ§Ä±k kaynaklÄ± bÃ¼yÃ¼k veri iÅŸleme motorudur. Bellek iÃ§i veri iÅŸleme yeteneÄŸi ile yÃ¼ksek hÄ±z sunar. AÅŸaÄŸÄ±da Spark ile veri analizi yapma Ã¶rneÄŸi:

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("BÃ¼yÃ¼k Veri UygulamasÄ±").getOrCreate()
df = spark.read.csv("data.csv")  # CSV dosyasÄ±nÄ± yÃ¼kleme
df.show()  # Veri Ã§erÃ§evesini gÃ¶sterme
```
Bu kod, bir CSV dosyasÄ±nÄ± Spark ile yÃ¼kler ve verileri gÃ¶rÃ¼ntÃ¼ler. Spark, bÃ¼yÃ¼k veri analizini hÄ±zlandÄ±rÄ±r.

### âœ… **Veri Ä°ÅŸleme ve Analizinde BÃ¼yÃ¼k Veri KullanÄ±mÄ±**

BÃ¼yÃ¼k veri analitiÄŸi, bÃ¼yÃ¼k veri kÃ¼mesi Ã¼zerinde gerÃ§ekleÅŸtirilen analizlerdir. Spark ve Hadoop gibi araÃ§lar, verilerin daha hÄ±zlÄ± iÅŸlenmesini ve analiz edilmesini saÄŸlar. Bu sÃ¼reÃ§ler, iÅŸ zekasÄ± uygulamalarÄ±, makine Ã¶ÄŸrenimi modelleri ve veri gÃ¶rselleÅŸtirme iÃ§in kritik Ã¶neme sahiptir.

BÃ¼yÃ¼k veri analitiÄŸi, ÅŸirketlerin daha doÄŸru tahminlerde bulunmasÄ±na ve daha iyi kararlar almasÄ±na olanak tanÄ±r. Ã–rneÄŸin, mÃ¼ÅŸteri davranÄ±ÅŸÄ±nÄ± analiz ederek hedefli pazarlama stratejileri geliÅŸtirebilirler.

---


## ğŸ“Œ 12.9 Zaman Serisi Analizi

Zaman serisi analizi, zamanla deÄŸiÅŸen verilerin analizi iÃ§in kullanÄ±lan istatistiksel bir yÃ¶ntemdir. Zaman serileri genellikle finansal veriler, hava durumu verileri, ekonomik gÃ¶stergeler gibi zamanla deÄŸiÅŸen olaylarÄ± anlamak iÃ§in kullanÄ±lÄ±r.

### âœ… **Zaman Serisi Nedir?**

Zaman serisi, belirli bir zaman diliminde dÃ¼zenli aralÄ±klarla toplanmÄ±ÅŸ verilerdir. Bu veriler genellikle aÅŸaÄŸÄ±daki bileÅŸenleri iÃ§erir:

1. **Trend**: Zaman iÃ§indeki genel eÄŸilim, artÄ±ÅŸ veya azalma gÃ¶sterir.
2. **Mevsimsellik**: Belirli dÃ¶nemlerde tekrarlanan dÃ¶ngÃ¼sel deÄŸiÅŸimlere iÅŸaret eder.
3. **DuyarlÄ±lÄ±k**: Verilerin rastgele dalgalanmasÄ±nÄ± gÃ¶sterir.

### âœ… **Zaman Serisi Analizinde KullanÄ±lan YÃ¶ntemler**

#### ğŸ› ï¸ **ARIMA (Otoregresif Entegre Hareketli Ortalama)**

ARIMA, zaman serisi verilerinin tahmini iÃ§in yaygÄ±n olarak kullanÄ±lan bir yÃ¶ntemdir. Bu model, Ã¼Ã§ bileÅŸen iÃ§erir:

- **AR (Otoregresif)**: GeÃ§miÅŸ verilerin etkisini iÃ§erir.
- **I (Entegre)**: Verinin duraÄŸan hale getirilmesi iÃ§in fark alma iÅŸlemini temsil eder.
- **MA (Hareketli Ortalama)**: HatalarÄ±n ortalamasÄ±nÄ± kullanarak tahminlerde bulunur.

Zaman serisi verilerini ARIMA modeliyle analiz etmek iÃ§in aÅŸaÄŸÄ±daki gibi bir kod kullanÄ±labilir:

```python
import pandas as pd
from statsmodels.tsa.arima.model import ARIMA

# Zaman serisi verisinin yÃ¼klenmesi
data = pd.read_csv('time_series_data.csv', parse_dates=['date'], index_col='date')

# ARIMA modelinin oluÅŸturulmasÄ± ve eÄŸitilmesi
model = ARIMA(data['value'], order=(1, 1, 1))
model_fit = model.fit()

# Tahminlerin yapÄ±lmasÄ±
forecast = model_fit.forecast(steps=5)
print("Gelecek 5 adÄ±m iÃ§in tahminler:", forecast)
```

Bu kod, bir zaman serisi verisini kullanarak ARIMA modelini oluÅŸturur ve gelecekteki beÅŸ veri noktasÄ± iÃ§in tahminler yapar.

#### ğŸ“ˆ **Mevsimsel Dekompozisyon**

Zaman serisi verilerini analiz etmek iÃ§in bir diÄŸer yÃ¶ntem de mevsimsel dekompozisyondur. Bu yÃ¶ntem, zaman serisini trend, mevsimsellik ve rastgele bileÅŸenlere ayÄ±rÄ±r. Bu sayede, her bir bileÅŸeni ayrÄ± ayrÄ± analiz etmek mÃ¼mkÃ¼n olur.

```python
from statsmodels.tsa.seasonal import seasonal_decompose

# Zaman serisi verisinin dekompozisyonu
decomposition = seasonal_decompose(data['value'], model='additive')
decomposition.plot()
```

Bu kod, zaman serisi verisinin bileÅŸenlerini gÃ¶rselleÅŸtirir, bÃ¶ylece verinin genel eÄŸilimi ve mevsimsel etkileri daha iyi anlaÅŸÄ±lÄ±r.

---

## ğŸ“Œ 12.10 Model DeÄŸerlendirme ve DoÄŸrulama

Model deÄŸerlendirme, oluÅŸturulan modelin ne kadar iyi performans gÃ¶sterdiÄŸini belirlemek iÃ§in kullanÄ±lan yÃ¶ntemlerdir. Bu sÃ¼reÃ§, modelin genelleme yeteneÄŸini anlamaya yardÄ±mcÄ± olur.

### âœ… **Model DeÄŸerlendirme YÃ¶ntemleri**

#### ğŸ” **KarmaÅŸÄ±klÄ±k ve AÅŸÄ±rÄ± Uydurma**

AÅŸÄ±rÄ± uydurma, modelin eÄŸitim verisine aÅŸÄ±rÄ± uyum saÄŸlamasÄ± ve test verisinde zayÄ±f performans gÃ¶stermesi durumudur. Modelin karmaÅŸÄ±klÄ±ÄŸÄ±, bu sorunu artÄ±rabilir. Bu nedenle, model deÄŸerlendirmesi yaparken karmaÅŸÄ±klÄ±k ve aÅŸÄ±rÄ± uydurmanÄ±n gÃ¶z Ã¶nÃ¼nde bulundurulmasÄ± Ã¶nemlidir.

#### ğŸ“Š **KayÄ±p FonksiyonlarÄ±**

KayÄ±p fonksiyonu, modelin tahmin hatalarÄ±nÄ± Ã¶lÃ§en bir Ã¶lÃ§Ã¼ttÃ¼r. Ä°ki yaygÄ±n kayÄ±p fonksiyonu ÅŸunlardÄ±r:

- **Mean Squared Error (MSE)**: Tahminlerin gerÃ§ekteki deÄŸerlerden ne kadar uzak olduÄŸunu Ã¶lÃ§er.
  
```python
from sklearn.metrics import mean_squared_error

# GerÃ§ek deÄŸerler ve tahminler
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

# MSE hesaplama
mse = mean_squared_error(y_true, y_pred)
print("MSE:", mse)
```

- **Log Loss**: SÄ±nÄ±flandÄ±rma problemlerinde kullanÄ±lÄ±r ve modelin tahmin ettiÄŸi olasÄ±lÄ±klarÄ±n gerÃ§ek etiketlerle olan uyumunu Ã¶lÃ§er.

#### ğŸ“ˆ **Ã‡apraz DoÄŸrulama**

Ã‡apraz doÄŸrulama, modelin farklÄ± veri parÃ§alarÄ± Ã¼zerinde test edilmesini saÄŸlayarak modelin genelleme yeteneÄŸini artÄ±rÄ±r. K-fold Ã§apraz doÄŸrulama, en yaygÄ±n kullanÄ±lan yÃ¶ntemlerden biridir. Veri seti K alt kÃ¼meye bÃ¶lÃ¼nÃ¼r ve her bir alt kÃ¼me test verisi olarak kullanÄ±lÄ±rken kalan alt kÃ¼meler eÄŸitim seti olarak kullanÄ±lÄ±r.

```python
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor()
scores = cross_val_score(model, X, y, cv=5)
print("Ã‡apraz DoÄŸrulama SkorlarÄ±:", scores)
```

---

## ğŸ“Œ 12.11 Proje YÃ¶netimi ve Veri Bilimi

Veri bilimi projeleri genellikle karmaÅŸÄ±k ve disiplinler arasÄ±dÄ±r. Bu projelerin baÅŸarÄ±yla yÃ¶netilmesi iÃ§in aÅŸaÄŸÄ±daki adÄ±mlar Ã¶nemlidir:

### âœ… **Proje TanÄ±mlama**

Projenin kapsamÄ±nÄ±n ve hedeflerinin belirlenmesi kritik Ã¶neme sahiptir. Proje tanÄ±mlarken ÅŸu sorularÄ± yanÄ±tlamak Ã¶nemlidir:

- Proje neyi baÅŸarmayÄ± amaÃ§lÄ±yor?
- Hangi veriler kullanÄ±lacak?
- Hedef kitle kim?

### âœ… **Veri Toplama ve Ã–n Ä°ÅŸleme**

Veri toplama ve Ã¶n iÅŸleme sÃ¼reci, veri bilimi projelerinin en Ã¶nemli aÅŸamalarÄ±ndan biridir. Verilerin temizlenmesi, dÃ¼zeltilmesi ve dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi, analizin kalitesini artÄ±rÄ±r. AÅŸaÄŸÄ±da bazÄ± veri Ã¶n iÅŸleme adÄ±mlarÄ± verilmiÅŸtir:

- **Veri Temizleme**: Eksik ve hatalÄ± verilerin giderilmesi.
- **Veri DÃ¶nÃ¼ÅŸÃ¼mÃ¼**: Verilerin uygun formatlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi.
- **Ã–znitelik SeÃ§imi**: Modelin eÄŸitimi iÃ§in en Ã¶nemli Ã¶zelliklerin belirlenmesi.

#### ğŸ“Š **Model GeliÅŸtirme ve Test Etme**

Model geliÅŸtirme aÅŸamasÄ±nda, uygun algoritmalar seÃ§ilir ve bu algoritmalar ile model eÄŸitilir. Modelin test edilmesi ise yukarÄ±da belirtilen deÄŸerlendirme yÃ¶ntemleri kullanÄ±larak gerÃ§ekleÅŸtirilir.

#### ğŸ“ˆ **SonuÃ§larÄ±n Sunumu**

SonuÃ§larÄ±n etkili bir ÅŸekilde sunulmasÄ±, projenin baÅŸarÄ±sÄ±nÄ± artÄ±rÄ±r. GÃ¶rselleÅŸtirme araÃ§larÄ± kullanarak elde edilen sonuÃ§larÄ±n grafiksel olarak sunulmasÄ±, bilgiyi daha anlaÅŸÄ±lÄ±r hale getirir.